{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Checker\n",
    "\n",
    "This notebook allows you to interactively check the audio-to-phoneme alignment for segmented recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display, clear_output\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from data_prepare.audio_utils import get_sampling_rate\n",
    "\n",
    "# Use inline backend explicitly\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "#DATA_DIR = '../datalocal/v260210_24kHz/readtext_split'\n",
    "DATA_DIR = '../datalocal/v260210_24kHz/sentences'\n",
    "\n",
    "if not Path(DATA_DIR).exists():\n",
    "    print(f\"Warning: DATA_DIR {DATA_DIR} not found. Please run the segmentation script first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_data(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    all_files = sorted(list(data_dir.glob(\"*.wav\")))\n",
    "    \n",
    "    speakers = {}\n",
    "    for f in all_files:\n",
    "        speaker_id = f.stem.split('_')[0]\n",
    "        if speaker_id not in speakers:\n",
    "            speakers[speaker_id] = []\n",
    "        \n",
    "        txt_path = f.with_suffix('.txt')\n",
    "        text = \"\"\n",
    "        if txt_path.exists():\n",
    "            with open(txt_path, 'r', encoding='utf-8') as tf:\n",
    "                text = tf.read()\n",
    "        \n",
    "        speakers[speaker_id].append({\n",
    "            'stem': f.stem,\n",
    "            'text': text\n",
    "        })\n",
    "    \n",
    "    return speakers\n",
    "\n",
    "SPEAKER_DATA = get_speaker_data(DATA_DIR)\n",
    "SPEAKER_LIST = sorted(list(SPEAKER_DATA.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alignment(stem):\n",
    "    wav_path = Path(DATA_DIR) / f\"{stem}.wav\"\n",
    "    \n",
    "    # Check for CSV in multiple locations\n",
    "    csv_path = Path(DATA_DIR) / f\"{stem}.csv\"\n",
    "    if not csv_path.exists():\n",
    "        # Check subfolder\n",
    "        csv_path = Path(DATA_DIR) / \"ali_phoneme\" / f\"{stem}.csv\"\n",
    "    \n",
    "    if not wav_path.exists() or not csv_path.exists():\n",
    "        print(f\"Error: Missing files for {stem}\")\n",
    "        print(f\"WAV: {wav_path.exists()}, CSV: {csv_path.exists()} (Checked: {csv_path})\")\n",
    "        return\n",
    "    \n",
    "    y, sr = librosa.load(wav_path, sr=None)\n",
    "    df = pd.read_csv(csv_path, sep=';')\n",
    "    \n",
    "    # Create figure without showing it yet\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8), sharex=True)\n",
    "    \n",
    "    librosa.display.waveshow(y, sr=sr, ax=ax1, alpha=0.5)\n",
    "    ax1.set_title(f\"Alignment for {stem}\")\n",
    "    ax1.set_ylabel(\"Amplitude\")\n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=ax2)\n",
    "    ax2.set_ylabel(\"Hz\")\n",
    "    \n",
    "    # Boundaries and Labels\n",
    "    for _, row in df.iterrows():\n",
    "        start_sec = row['BEGIN'] / sr\n",
    "        ax1.axvline(start_sec, color='gray', linestyle='--', alpha=0.3)\n",
    "        ax2.axvline(start_sec, color='white', linestyle='--', alpha=0.3)\n",
    "        mid_sec = start_sec + (row['DURATION'] / (2 * sr))\n",
    "        ax1.text(mid_sec, -0.6, row['MAU'], color='red', fontsize=9, horizontalalignment='center')\n",
    "\n",
    "    df['block'] = (df['TOKEN'] != df['TOKEN'].shift()).cumsum()\n",
    "    word_boundaries = df.groupby(['block', 'TOKEN']).agg({\n",
    "        'BEGIN': 'min', \n",
    "        'DURATION': 'sum', \n",
    "        'ORT': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    for _, row in word_boundaries.iterrows():\n",
    "        start_sec = row['BEGIN'] / sr\n",
    "        label = str(row['ORT']) if row['TOKEN'] >= 0 else '<p:>'\n",
    "        color = 'blue' if row['TOKEN'] >= 0 else 'green'\n",
    "        \n",
    "        ax1.axvline(start_sec, color=color, linewidth=2, alpha=0.6)\n",
    "        ax2.axvline(start_sec, color='cyan' if row['TOKEN'] >= 0 else 'lightgreen', linewidth=2, alpha=0.6)\n",
    "        \n",
    "        mid_sec = start_sec + (row['DURATION'] / (2 * sr))\n",
    "        ax1.text(mid_sec, -0.9, label, color=color, fontsize=12, fontweight='bold', horizontalalignment='center')\n",
    "\n",
    "    ax1.axvline(len(y)/sr, color='gray', linestyle='--', alpha=0.3)\n",
    "    ax2.axvline(len(y)/sr, color='white', linestyle='--', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig) \n",
    "    display(Audio(y, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb91d61b7a54ae2b9d56747e5d6c9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Speaker:', options=('001PD', '002PD', '003PD', '004PD', '005PD', '006PD',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INTERACTIVE WIDGETS\n",
    "speaker_select = widgets.Dropdown(options=SPEAKER_LIST, description='Speaker:')\n",
    "segment_select = widgets.Dropdown(description='Segment:')\n",
    "output_plot = widgets.Output()\n",
    "output_table = widgets.Output()\n",
    "\n",
    "def update_segments(change=None):\n",
    "    speaker_id = speaker_select.value\n",
    "    segments = SPEAKER_DATA.get(speaker_id, [])\n",
    "    \n",
    "    # Update segment list\n",
    "    segment_select.options = [s['stem'] for s in segments]\n",
    "    \n",
    "    # Show summary table\n",
    "    with output_table:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(segments))\n",
    "\n",
    "def on_selection_change(change=None):\n",
    "    if change and change['type'] != 'change' or change['name'] != 'value':\n",
    "        return\n",
    "        \n",
    "    with output_plot:\n",
    "        clear_output(wait=True)\n",
    "        if segment_select.value:\n",
    "            plot_alignment(segment_select.value)\n",
    "\n",
    "# Observers\n",
    "speaker_select.observe(update_segments, names='value')\n",
    "segment_select.observe(on_selection_change, names='value')\n",
    "\n",
    "# Display UI Layout\n",
    "display(widgets.VBox([\n",
    "    speaker_select, \n",
    "    segment_select, \n",
    "    widgets.HTML(\"<b>Segments for selected speaker:</b>\"),\n",
    "    output_table, \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    output_plot\n",
    "]))\n",
    "\n",
    "# Manual trigger for initial display\n",
    "update_segments()\n",
    "if segment_select.value:\n",
    "    on_selection_change({'type': 'change', 'name': 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
